{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üö© Using `redflag` with `sklearn`\n",
    "\n",
    "As well as using `redflag`'s functions directly (see `Basic_usage.ipynb`), `redflag` has some `sklearn` transformers that you can use to detect possible issues in your data. \n",
    "\n",
    "‚ö†Ô∏è **Note that these transformers do not transform your data, they only raise warnings (red flags) if they find issues.**\n",
    "\n",
    "Let's load some example data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Depth</th>\n",
       "      <td>3966.0</td>\n",
       "      <td>882.674555</td>\n",
       "      <td>40.150056</td>\n",
       "      <td>784.402800</td>\n",
       "      <td>858.012000</td>\n",
       "      <td>888.339600</td>\n",
       "      <td>913.028400</td>\n",
       "      <td>963.320400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RelPos</th>\n",
       "      <td>3966.0</td>\n",
       "      <td>0.524999</td>\n",
       "      <td>0.286375</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.282000</td>\n",
       "      <td>0.531000</td>\n",
       "      <td>0.773000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marine</th>\n",
       "      <td>3966.0</td>\n",
       "      <td>1.325013</td>\n",
       "      <td>0.589539</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GR</th>\n",
       "      <td>3966.0</td>\n",
       "      <td>64.367899</td>\n",
       "      <td>28.414603</td>\n",
       "      <td>12.036000</td>\n",
       "      <td>45.311250</td>\n",
       "      <td>64.840000</td>\n",
       "      <td>78.809750</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ILD</th>\n",
       "      <td>3966.0</td>\n",
       "      <td>5.240308</td>\n",
       "      <td>3.190416</td>\n",
       "      <td>0.340408</td>\n",
       "      <td>3.169567</td>\n",
       "      <td>4.305266</td>\n",
       "      <td>6.664234</td>\n",
       "      <td>32.136605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeltaPHI</th>\n",
       "      <td>3966.0</td>\n",
       "      <td>3.469088</td>\n",
       "      <td>4.922310</td>\n",
       "      <td>-21.832000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.292500</td>\n",
       "      <td>6.124750</td>\n",
       "      <td>18.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PHIND</th>\n",
       "      <td>3966.0</td>\n",
       "      <td>13.008807</td>\n",
       "      <td>6.936391</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>8.196250</td>\n",
       "      <td>11.781500</td>\n",
       "      <td>16.050000</td>\n",
       "      <td>52.369000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PE</th>\n",
       "      <td>3966.0</td>\n",
       "      <td>3.686427</td>\n",
       "      <td>0.815113</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>3.123000</td>\n",
       "      <td>3.514500</td>\n",
       "      <td>4.241750</td>\n",
       "      <td>8.094000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Facies</th>\n",
       "      <td>3966.0</td>\n",
       "      <td>4.471004</td>\n",
       "      <td>2.406180</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LATITUDE</th>\n",
       "      <td>3966.0</td>\n",
       "      <td>37.632575</td>\n",
       "      <td>0.299398</td>\n",
       "      <td>37.180732</td>\n",
       "      <td>37.356426</td>\n",
       "      <td>37.500380</td>\n",
       "      <td>37.910583</td>\n",
       "      <td>38.063373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LONGITUDE</th>\n",
       "      <td>3966.0</td>\n",
       "      <td>-101.294895</td>\n",
       "      <td>0.230454</td>\n",
       "      <td>-101.646452</td>\n",
       "      <td>-101.389189</td>\n",
       "      <td>-101.325130</td>\n",
       "      <td>-101.106045</td>\n",
       "      <td>-100.987305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ILD_log10</th>\n",
       "      <td>3966.0</td>\n",
       "      <td>0.648860</td>\n",
       "      <td>0.251542</td>\n",
       "      <td>-0.468000</td>\n",
       "      <td>0.501000</td>\n",
       "      <td>0.634000</td>\n",
       "      <td>0.823750</td>\n",
       "      <td>1.507000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RHOB</th>\n",
       "      <td>3966.0</td>\n",
       "      <td>2288.861692</td>\n",
       "      <td>218.038459</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>2201.007475</td>\n",
       "      <td>2342.202051</td>\n",
       "      <td>2434.166399</td>\n",
       "      <td>2802.871147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            count         mean         std          min          25%  \\\n",
       "Depth      3966.0   882.674555   40.150056   784.402800   858.012000   \n",
       "RelPos     3966.0     0.524999    0.286375     0.010000     0.282000   \n",
       "Marine     3966.0     1.325013    0.589539     0.000000     1.000000   \n",
       "GR         3966.0    64.367899   28.414603    12.036000    45.311250   \n",
       "ILD        3966.0     5.240308    3.190416     0.340408     3.169567   \n",
       "DeltaPHI   3966.0     3.469088    4.922310   -21.832000     1.000000   \n",
       "PHIND      3966.0    13.008807    6.936391     0.550000     8.196250   \n",
       "PE         3966.0     3.686427    0.815113     0.200000     3.123000   \n",
       "Facies     3966.0     4.471004    2.406180     1.000000     2.000000   \n",
       "LATITUDE   3966.0    37.632575    0.299398    37.180732    37.356426   \n",
       "LONGITUDE  3966.0  -101.294895    0.230454  -101.646452  -101.389189   \n",
       "ILD_log10  3966.0     0.648860    0.251542    -0.468000     0.501000   \n",
       "RHOB       3966.0  2288.861692  218.038459  1500.000000  2201.007475   \n",
       "\n",
       "                   50%          75%          max  \n",
       "Depth       888.339600   913.028400   963.320400  \n",
       "RelPos        0.531000     0.773000     1.000000  \n",
       "Marine        1.000000     2.000000     2.000000  \n",
       "GR           64.840000    78.809750   200.000000  \n",
       "ILD           4.305266     6.664234    32.136605  \n",
       "DeltaPHI      3.292500     6.124750    18.600000  \n",
       "PHIND        11.781500    16.050000    52.369000  \n",
       "PE            3.514500     4.241750     8.094000  \n",
       "Facies        4.000000     6.000000     9.000000  \n",
       "LATITUDE     37.500380    37.910583    38.063373  \n",
       "LONGITUDE  -101.325130  -101.106045  -100.987305  \n",
       "ILD_log10     0.634000     0.823750     1.507000  \n",
       "RHOB       2342.202051  2434.166399  2802.871147  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('https://geocomp.s3.amazonaws.com/data/Panoma_training_data.csv')\n",
    "\n",
    "# Look at the transposed summary: each column in the DataFrame is a row here.\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the features (e.g. GR, RHOB) are not **independent** records; they are correlated to themselves in depth.\n",
    "\n",
    "Furthermore, some of these features are clipped, e.g. the GR feature is clipped at a max value of 200:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='GR', ylabel='Count'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.histplot(df['GR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will split this dataset by group (well name):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['GR', 'RHOB', 'PE']\n",
    "\n",
    "test_wells = ['CRAWFORD', 'STUART']\n",
    "\n",
    "test_flag = df['Well Name'].isin(test_wells)\n",
    "\n",
    "X_test = df.loc[test_flag, features]\n",
    "y_test = df.loc[test_flag, 'Lithology']\n",
    "\n",
    "X_train = df.loc[~test_flag, features]\n",
    "y_train = df.loc[~test_flag, 'Lithology']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the `redflag` pipeline\n",
    "\n",
    "There is a [`sklearn.pipeline.Pipeline`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) you can use, containing all of the detectors. (At the time of writing, there are three components, but this is set to grow.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('rf.imbalance', ImbalanceDetector()),\n",
       "                ('rf.clip', ClipDetector()),\n",
       "                ('rf.correlation', CorrelationDetector()),\n",
       "                ('rf.outlier', OutlierDetector()),\n",
       "                ('rf.distributions', DistributionComparator())])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import redflag as rf\n",
    "\n",
    "rf.pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this in another pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('pipeline',\n",
       "                 Pipeline(steps=[('rf.imbalance', ImbalanceDetector()),\n",
       "                                 ('rf.clip', ClipDetector()),\n",
       "                                 ('rf.correlation', CorrelationDetector()),\n",
       "                                 ('rf.outlier', OutlierDetector()),\n",
       "                                 ('rf.distributions',\n",
       "                                  DistributionComparator())])),\n",
       "                ('svc', SVC())])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(), rf.pipeline, SVC())\n",
    "pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the `fit` phase, the `redflag` transformers do three things:\n",
    "\n",
    "- Check the target `y` for imbalance (if it is categorical).\n",
    "- Check the input features `X` for issues like clipping and self-correlation.\n",
    "- Learn the input feature distributions for later comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üö© The labels are imbalanced by more than the threshold (0.420 > 0.400).\n",
      "üö© Features 0, 1 may have clipped values.\n",
      "üö© Features 0, 1, 2 may have correlated values.\n",
      "üö© There are more outliers than expected in the training data (349 vs 31).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('pipeline',\n",
       "                 Pipeline(steps=[('rf.imbalance', ImbalanceDetector()),\n",
       "                                 ('rf.clip', ClipDetector()),\n",
       "                                 ('rf.correlation', CorrelationDetector()),\n",
       "                                 ('rf.outlier',\n",
       "                                  OutlierDetector(threshold=3.3682141715600706)),\n",
       "                                 ('rf.distributions',\n",
       "                                  DistributionComparator())])),\n",
       "                ('svc', SVC())])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we pass in data for prediction, `redflag` checks the new inputs. There are two categories of check:\n",
    "\n",
    "- Check for first-order issues, e.g. for clipping, or self-correlation.\n",
    "- Compare statistics to the training data, e.g. to compare the distribution of the data or look for outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üö© Feature 0 may have clipped values.\n",
      "üö© Features 0, 1, 2 may have correlated values.\n",
      "üö© There are more outliers than expected in the data (30 vs 8).\n",
      "üö© Feature 2 has a distribution that is different from training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['siltstone', 'siltstone', 'siltstone', 'siltstone', 'siltstone',\n",
       "       'siltstone', 'siltstone', 'siltstone', 'siltstone', 'siltstone',\n",
       "       'siltstone', 'siltstone', 'siltstone', 'siltstone', 'siltstone',\n",
       "       'siltstone', 'siltstone', 'siltstone', 'siltstone', 'siltstone'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = pipe.predict(X_test)\n",
    "y_pred[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But you can't pass arguments to the `redflag_pipeline` components yet, for example to change the sensitivity of the `DistributionComparator`. To do that, use them separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the 'detector' transformers\n",
    "\n",
    "Let's construct a pipeline from `redflag`'s transformers directly.\n",
    "\n",
    "Let's drop the clipped records of the GR log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df['GR'] < 200]\n",
    "\n",
    "test_flag = df['Well Name'].isin(test_wells)\n",
    "\n",
    "X_test = df.loc[test_flag, features]\n",
    "y_test = df.loc[test_flag, 'Lithology']\n",
    "\n",
    "X_train = df.loc[~test_flag, features]\n",
    "y_train = df.loc[~test_flag, 'Lithology']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know all this data is correlated to itself, so we can leave that check out.\n",
    "\n",
    "We don't think the class imbalance is too troubling, so we raise the threshold on that.\n",
    "\n",
    "We'll lower the confidence level of the outlier detector to 80% (i.e. we expect 20% of the data points will likely qualify as outliers). This might still trigger the detector in the training data.\n",
    "\n",
    "Finally, we'll lower the threshold for the distribution comparison. This is the minimum Wasserstein distance required to trigger the warning.\n",
    "\n",
    "So here's the new pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(StandardScaler(),\n",
    "                     rf.ImbalanceDetector(threshold=0.5),\n",
    "                     rf.ClipDetector(),\n",
    "                     rf.OutlierDetector(p=0.80),\n",
    "                     rf.DistributionComparator(threshold=0.25),\n",
    "                     SVC())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, feature 0 is no longer clipped, and the correlation detection is not being run. So we expect to see only the outlier issue, and the clipping issue with the RHOB column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üö© Feature 1 may have clipped values.\n",
      "üö© There are more outliers than expected in the training data (839 vs 626).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('imbalancedetector', ImbalanceDetector(threshold=0.5)),\n",
       "                ('clipdetector', ClipDetector()),\n",
       "                ('outlierdetector',\n",
       "                 OutlierDetector(p=0.8, threshold=2.154443705823081)),\n",
       "                ('distributioncomparator',\n",
       "                 DistributionComparator(threshold=0.25)),\n",
       "                ('svc', SVC())])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test dataset does not trigger the higher threshold for outliers. But with the new lower Wasserstein threshold, the distribution comparison fails for all of the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üö© Features 0, 1, 2 have distributions that are different from training.\n"
     ]
    }
   ],
   "source": [
    "y_pred = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What to do about the warnings\n",
    "\n",
    "If one of the detectors triggers, what should you do? Here are some ideas:\n",
    "\n",
    "\n",
    "### `ImbalanceDetector`\n",
    "\n",
    "- Check `rf.class_counts(y)` to see the support for each class in the dataset.\n",
    "- Check `rf.minority_classes(y)` to see which classes are considered 'minority'.\n",
    "\n",
    "This detector does not run during `transform`, only during `fit`. Usually, we don't worry about imbalance in data we are predicting on. If this is a concern for you, you can use `fit` on it (and make a GitHub Issue about it, because we could add an option to run during transform as well).\n",
    "\n",
    "\n",
    "### `ClipDetector`\n",
    "\n",
    "- Make sure the clipping values seem reasonable and do not lose a lot of dynamic range in the data (e.g. don't clip daily temperatures for Europe at 0 and 25 deg C).\n",
    "- Check that the clipped data cannot be dealt with in some other way (e.g. you can attenuate very large values with a log transformation, if it makes sense in your data).\n",
    "- Check that the clipped data should not simply be dropped from the dataset (e.g. if there are only a few values out of many, or if the other features also look suspicious for those records).\n",
    "\n",
    "You may or may not be concerned about clipping. You may want to try training your models with and without the clipped records, to see if they make a difference to the model performance. I'm not aware of any research on this.\n",
    "\n",
    "\n",
    "### `CorrelationDetector`\n",
    "\n",
    "If the data is correlated to shifted versions of itself, e.g. because the data points are contiguous in time or space (daily temperature records, spatial measurements of rock properties, etc), then the so-called [IID assumption](https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables) fails. In particular, your records are not independent. One of the big pitfalls with non-independent data is randomly splitting the data into train and test sets &mdash; you must not do this, it will result in information leakage and thus over-optimistic model evaulation. Instead, you should split the data using contiguous groups (date ranges, patient ID, borehole, or similar).\n",
    "\n",
    "\n",
    "### `OutlierDetector`\n",
    "\n",
    "There are a lot of ways of looking for outliers in data. The outlier detector only implements one strategy:\n",
    "\n",
    "- Learn the robust location and covariance of the training data (you can think of these as outlier-insensitive, multi-dimensional analogs to mean and variance in a single random variable).\n",
    "- As with the Gaussian distribution, we expect a certain number of samples to fall far from the centre of this distribution. For example, we expect 99.7% of values to be within 3 standard deviations of the mean.\n",
    "- So, given a confidence level like 99.7%, `redflag` counts how many values are more than 3 SD's away. If there are more than expected (e.g.  we expect 3 samples out of 1000), the detector is triggered.\n",
    "- The default confidence level is 99% (you expect 1% of the data to be noise), but you can change it.\n",
    "\n",
    "So the location and covariance are learned from the training data; the detector then runs on the training data and on future datasets during the prediction phase (test, val, and in production).\n",
    "\n",
    "If the detector is triggered, you should check which samples are considered outliers with `rf.get_outliers(method='mah', p=0.99)` (without your value for `p`). This function returns the _indices_ of the outlier samples. You can also use `rf.expected_outliers(*X.shape, p=0.99)` to check how many outliers you'd expect in the dataset, for a given value of `p`/.\n",
    "\n",
    "You can check other methods, such as `iso` (isolation forest) to see if those also consider those samples to be outliers or not. If you think the samples are okay, you should keep them. If you think they are noise, you could remove them &mdash; but remember your model will not 'know' about these kinds of data points in the future and you should therefore remove them from future datasets too, before making predictions on them.\n",
    "\n",
    "\n",
    "### `DistributionComparator`\n",
    "\n",
    "Here's what this thing does:\n",
    "\n",
    "- When you call `fit` (e.g. during training), the detector learns the empirical, binned distributions of your features, one at a time. No warnings can be emitted during fitting, you are only learning the distributions.\n",
    "- When you call `transform` (e.g. during evaluation, testing, or in production), the detector compares the distributions in the data to those that were learned during fitting.\n",
    "- The comparison uses the [1-Wasserstein distance](https://en.wikipedia.org/wiki/Wasserstein_metric), or \"earth mover's distance\". Each feature is compared in turn; it is not a multivariate treatment. (If you'd like to see such a thing, please make a GitHub Issue, or have a crack at implementing it!)\n",
    "- If the distance is more than the threshold, 1 by default, the warning is triggered.\n",
    "\n",
    "If this detector triggers, it's a sign that you may have violated the 'identical  distribution' part of the [IID assumption](https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables). You should examine the distributions of the features in the training data vs the current data that triggered the detector. For example, you can do this visually with something like Seaborn's `displot` or `kdeplot` functions.\n",
    "\n",
    "A small difference, especially on just a few features, might just result from natural variance in the data and you may decide to ignore it. A large difference may be a result of forgetting to scale the data using the scaling parameters learned from the training data. A large difference could also result from trying to apply the model to a new 'domain', e.g. a new geographic location, set of patients, or type of widget. \n",
    "\n",
    "If you're in the model selection phase, it's possible that a different train/test split will give more comparable distributions.\n",
    "\n",
    "### Feature importance comparator (coming soon)\n",
    "\n",
    "- Negative importance suggests the feature is harming the prediction.\n",
    "- Very low positive importance (compared to other features) suggests the feature does not contain much useful information.\n",
    "- Very high importance in one or two features (compared to other features) suggests the feature(s) may be leaking information: check that it does not contain information about the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "redflag",
   "language": "python",
   "name": "redflag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
